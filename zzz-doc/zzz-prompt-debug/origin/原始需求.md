## 架构图

![架构图](https://cdn.nlark.com/yuque/0/2026/png/60410034/1770204834398-dfc6182b-bb7a-4fb0-bd7f-5eb4db428020.png?x-oss-process=image%2Fformat%2Cwebp)

## 需求
1. 就是需求是想写一个类似于桌面宠物，或者桌面陪伴机器人，可以偶尔跑到我自己的鼠标上，也可以直接快捷键打开对话框
2. 形象可以是一个live2d，有rag形成记忆，mcp作为手脚，llm作为大脑
3. 那是不是类似一个gemini cli会比较好用？还可以默默记录你的生活习惯，但是不能太隐私，每天用什么应用用了多久，屏幕使用时间，在哪个页面停留很久，浏览记录的分析，之类的，
4. 最好还可以使用gptvits，或者直接导入语音或者llm模型
5. 我想调用摄像头分析使用者的表情，心理可以吗，有现成可以分析表情的模型吗，分析表情能不能和使用者正在电脑上干的事结合在一起
6. 如果把这些都写成mcp会不会好一点，让ai自己调用，自己分析
7. 总的来说前端框架就是electron后端就是py
8. 接下来就是编写mcp？
9. 让live2d动起来，让ai去控制，前端最好使用什么框架？如果想实现面补的效果，或者不同表情之前顺滑的切换，应该使用什么框架，或者技术
10. 这样可以吗，没有那么多多余的东西，好像一个人，
11. 最开始来到你的电脑上的时候，是怕生的，随着运行时间的增加，rag的不断扩大，变得熟悉，感情开始加深，变得越来越了解你，了解你的生活习惯，使用电脑的习惯，随着rag或者是上下文的不断增加，开始出现幻觉，不断走向末路，最后只能清空rag重新开始
12. 让ai参考rag中知识一般怎么做，如何对电脑的的使用时间，浏览器记录，或者软件的使用时长来对我自己进行分析，爱好习惯分析，这些如何和mcp，rag联系在一起，让ai知道我自己的习惯，这是我的大概需求，就是前端是一个live2d模型，需要用代码控制表情，行为，动作，需要控制模型在屏幕上面的移动